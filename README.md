## Replication Package For Paper: Learning CNN-Encoded Propositions for Robotic Programming from Few Demonstrations

[View on Github](https://github.com/LCEPRPFD/LCEPRPFD.github.io)

### Code

## We refactor the code of this project, which can be found at this.

---

### Dataset

- [traj_capability](https://1drv.ms/u/s!AtQlfXL28GxeajG8PychjufKca8?e=bMah0V): a large training set of robot's capability execution. This is a serialized dictionary dataset with four keys: 'move', 'pick_cube', 'transport' and 'place_cube'. The value of each key contains a list of trajectories for an capability.
- [traj_demonstration](https://1drv.ms/u/s!An_sqEOHEaVaalbqMgGmadqPvqI?e=6wKFlF): a set of trajectories by executing TaskA. This is a serialized list dataset. Each element in the list is a dictionary object with four keys: 'move', 'pick_cube', 'transport' and 'place_cube'. The value of each key is a trajectory of an capability.

---

### capNet

<div align="center">
    <img src="https://github.com/LCEPRPFD/LCEPRPFD.github.io/blob/main/img/capnet.png"/>
</div>

The input to the $capNet$ is a $200 \times 65$ trajectory fragment. The first layer consists of two stacking LSTMs which is bidirectional and contain 128 hidden states.
It is followed by two fully-connected network blocks, each is composed of a dense layer, a batch normalization layer and a ReLU activation function layer. The hidden sizes are $256 \times 128$ and $128 \times 64$ respectively.
The output layer consists of a $64 \times 4$ dense layer followed by a dropout layer with $p = 0.5$. 
The multiple classification result is generated by a softmax layer.
During training the $capNet$, the Batch size is 256 and learning rate is 0.0003.

---

### baseNet and propNet

<div align="center">
    <img src="https://github.com/LCEPRPFD/LCEPRPFD.github.io/blob/main/img/propnet.png"/>
</div>

The input to the $capNet$ is a $50 \times 65$ trajectory action states.
The basic block is composed of a convolutional layer, followed by a batch normalization layer, a ReLU activation function layer and a max pooling layer with kernel size 2. 
The detail is shown as following.
| layer |          filter          | stride | padding |
|:-----:|:------------------------:|:------:|:-------:|
|   1   | 128 * 50 * 1 |    1   |    1    |
|   2   |  $64 \times 64 \times 3$ |    1   |    1    |
|   3   |  $64 \times 32 \times 3$ |    1   |    1    |
|   4   |  $32 \times 32 \times 3$ |    1   |    1    |

The output layer consists of a $64 \times 2$ dense layer and a softmax layer.

---


### Evaluations

- _TP_ (true positive) represents the correct evaluation of a proposition (i.e., evaluate the truth value) to an action which is completed correctly
- _TN_ (true negative) represents the correct evaluation of a proposition (i.e., evaluate the false value) to an action which is executed abnormally
- _FP_ (false positive) represents the incorrect evaluation of a proposition (i.e., evaluate the false value) to an action completed correctly.
- _FN_ (false negative) represents the incorrect evaluation of a proposition (i.e., evaluate the truth value) to an action executed abnormally.
- _cnt_ represents the total count of proposition evaluation performed during the program execution in an experiment, the accuracy is calculated by \#TP+\#TN/_cnt_, where \# means the count of the verdict.
- _SeR_ is short for stationary-environmental request. _VeR_ is short for variable-environmental request.
- _\#ES_ represents the count of the success during the executions. _\#EF_ represents the count of the failure.
- _TaskA_ represents a pick-and-place task. From the figure below, the Fetch robot is first guided to move close to TableA and then to pick up the cube. After catching the cube, the robot is guided to move to TableB and finally put the cube on the table.

<div align="center">
    <img src="https://github.com/LCEPRPFD/LCEPRPFD.github.io/blob/main/img/TaskA_scenario.png"/>
</div>

---

#### RQ1 General Accuracy

<!-- **Table: Accuracy of evaluating propositions in TaskA** -->
<center>Table: Accuracy of evaluating propositions in TaskA</center>
<table align="center">
    <tr align="center">
        <td></td>
        <td></td>
        <td>cnt</td>
        <td>#TP</td>
        <td>#TN </td>
        <td>#FP</td>
        <td>#FN</td>
        <td>Accuracy</td>
        <td>#ES</td>
        <td>#EF</td>
    </tr>
    <tr align="center">
        <td rowspan="2">Our method</td>
        <td>SeR</td>
        <td>152</td>
        <td>130</td>
        <td>8</td>
        <td>8</td>
        <td>6</td>
        <td>90.8%</td>
        <td>28</td>
        <td>8</td>
    </tr>
    <tr align="center">
        <td>VeR</td>
        <td>151</td>
        <td>120</td>
        <td>11</td>
        <td>15</td>
        <td>5</td>
        <td>86.8%</td>
        <td>19</td>
        <td>11</td>
    </tr>
    <tr align="center">
        <td rowspan="2">Baseline</td>
        <td>SeR</td>
        <td>184</td>
        <td>166</td>
        <td>14</td>
        <td>4</td>
        <td>0</td>
        <td>97.8%</td>
        <td>32</td>
        <td>14</td>
    </tr>
    <tr align="center"> 
        <td>VeR</td>
        <td>73</td>
        <td>25</td>
        <td>0</td>
        <td>48</td>
        <td>0</td>
        <td>34.2%</td>
        <td>2</td>
        <td>0</td>
    </tr>
</table>

This Table shows the comparision between our method and baseline. 
Each method is evaluated in both _SeR_ and _VeR_.
We uses the robotic program which is learned and generated from five demonstrations. 
The experiments is executed for 50 times.

---

#### RQ2: Impact of the Number of Demonstrations

<!-- **Table: Accuracy of evaluating propositions in TaskA for SeR under different demonstration counts** -->
<center>Table: Accuracy of evaluating propositions in TaskA for SeR under different demonstration counts</center>

<table align="center">
    <tr align="center">
        <td>#demonstration</td>
        <td>cnt</td>
        <td>#TP</td>
        <td>#TN </td>
        <td>#FP</td>
        <td>#FN</td>
        <td>Accuracy</td>
        <td>#ES</td>
        <td>#EF</td>
    </tr>
    <tr align="center">
        <td>1</td>
        <td>140</td>
        <td>100</td>
        <td>13</td>
        <td>19</td>
        <td>8</td>
        <td>80.7%</td>
        <td>10</td>
        <td>13</td>
    </tr>
    <tr align="center">
        <td>5</td>
        <td>152</td>
        <td>130</td>
        <td>8</td>
        <td>8</td>
        <td>6</td>
        <td>90.8%</td>
        <td>28</td>
        <td>8</td>
    </tr>
    <tr align="center">
        <td>10</td>
        <td>169</td>
        <td>148</td>
        <td>11</td>
        <td>10</td>
        <td>0</td>
        <td>94.1%</td>
        <td>29</td>
        <td>11</td>
    </tr>
    <tr align="center">
        <td>20</td>
        <td>159</td>
        <td>136</td>
        <td>15</td>
        <td>4</td>
        <td>4</td>
        <td>95.0%</td>
        <td>27</td>
        <td>15</td>
    </tr>
</table>

This table evaluates the impact of the number of demonstrations on our approach. 
To this end, we learn from 1, 5, 10 and 20 demonstrations in _SeR_.
The experiments is executed for 50 times.

---

#### RQ3: Impact of the Demonstrations under Difference Environment Settings

<!-- **Table: Accuracy of the program learned from demonstrations under different environment settings** -->
<center>Table: Accuracy of the program learned from demonstrations under different environment settings</center>

<table align="center">
    <tr align="center">
        <td>#demonstration</td>
        <td>cnt</td>
        <td>#TP</td>
        <td>#TN </td>
        <td>#FP</td>
        <td>#FN</td>
        <td>Accuracy</td>
        <td>#ES</td>
        <td>#EF</td>
    </tr>
    <tr align="center">
        <td>10</td>
        <td>162</td>
        <td>134</td>
        <td>11</td>
        <td>8</td>
        <td>9</td>
        <td>89.50%</td>
        <td>22</td>
        <td>11</td>
    </tr>
</table>

This table shows the evaluation of the impact of demonstrations conducted in different environment settings on the approach accuracy. 

<div align="center">
    <img src="https://github.com/LCEPRPFD/LCEPRPFD.github.io/blob/main/img/rq3_scenario.png"/>
</div>
<!-- ![rq3_scenario](/img/rq3_scenario.png)  -->

As shown in the figure, we change the environment by adding a new Table _TableC_ located outside the room.
We perform ten demonstrations in the new environment. 
Half of the demonstrations are performed in which the robot deliveries a cube from _TableA_ to _TableB_.
The rest demonstrations are performed to delivery a cube from _TableA_ to _TableC_.
By applying our approach, the action sequence is formulated to delivery a cube from _TableC_ to _TableB_.
The experiments is executed for 50 times

---

#### Video

The video will be uploaded later.
